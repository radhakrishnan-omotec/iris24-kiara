{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radhakrishnan-omotec/iris24-kiara/blob/main/Skin_Diseases_KiaraPatel_Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PET SKIN DISEASE CLASSIFICATION\n",
        "##Various types of Dog Skin diseases classification using CNN Model\n",
        "###Author: Kiara Patel\n",
        "**Abstract:**\n",
        "The global prevalence of autism affecting 1 in 100 children highlights a critical issue in social communication.\n",
        "Individuals on the spectrum grapple with language processing, leading to struggles in formulating responses.\n",
        "25 - 30% face challenges in developing functional language skills, resulting in communication hurdles that strain relationships and impede learning.\n",
        "Verbal communication difficulties lead to frustration and anxiety, affecting overall well-being."
      ],
      "metadata": {
        "id": "plOEshgGsCQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Image classification\n",
        "This tutorial shows how to classify images of flowers using a tf.keras.Sequential model and load data using tf.keras.utils.image_dataset_from_directory. It demonstrates the following concepts:\n",
        "\n",
        "####Efficiently loading a dataset off disk.\n",
        "Identifying overfitting and applying techniques to mitigate it, including data augmentation and dropout.\n",
        "This tutorial follows a basic machine learning workflow:\n",
        "\n",
        "**Examine and understand data<br>\n",
        "Build an input pipeline<br>\n",
        "Build the model<br>\n",
        "Train the model<br>\n",
        "Test the model<br>**\n",
        "\n",
        "Improve the model and repeat the process"
      ],
      "metadata": {
        "id": "s_eUQce2tHQS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle competitions download -c diabetic-retinopathy-detection\n",
        "\n",
        "!kaggle datasets download -d sovitrath/diabetic-retinopathy-224x224-gaussian-filtered"
      ],
      "metadata": {
        "id": "z5EJg_1dtYo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup\n",
        "Import TensorFlow and other necessary libraries:"
      ],
      "metadata": {
        "id": "Z8Pydr_GtbB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "h6A4D7rHtgfh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7TxUr1actkXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download and explore the dataset\n",
        "This tutorial uses a dataset of about photos of skin diease. The dataset contains five sub-directories, one per class:"
      ],
      "metadata": {
        "id": "EDQ5-dWHtmkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the competition data\n",
        "!unzip -q diabetic-retinopathy-detection.zip -d diabetic-retinopathy-detection\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip -q diabetic-retinopathy-224x224-gaussian-filtered.zip -d diabetic-retinopathy-224x224-gaussian-filtered"
      ],
      "metadata": {
        "id": "UnYZRd0Xtuvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**After downloading, you should now have a copy of the dataset available.**"
      ],
      "metadata": {
        "id": "nD8l8q4ftz-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "# Define the directory path\n",
        "data_dir = pathlib.Path('/content/diabetic-retinopathy-224x224-gaussian-filtered/gaussian_filtered_images/gaussian_filtered_images')\n",
        "# Specify the image file extensions to look for\n",
        "image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff'}\n",
        "# Use pathlib to find all image files in the directory and subdirectories\n",
        "image_files = [f for f in data_dir.rglob('*') if f.suffix.lower() in image_extensions]\n",
        "# Count the number of image files\n",
        "num_images = len(image_files)\n",
        "print(f\"Number of images: {num_images}\")"
      ],
      "metadata": {
        "id": "4EDx7x8NtxVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setup\n",
        "Import TensorFlow and other necessary libraries:"
      ],
      "metadata": {
        "id": "NlReUpqqspfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "xRNPk3Dbsdq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download and explore the dataset"
      ],
      "metadata": {
        "id": "ylvp5Jxsxxpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Connect to the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "W6OkNJv6xo2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Load the folder in the connected Google Drive\n",
        "import os\n",
        "\n",
        "# Change this path to the folder you want to analyze\n",
        "folder_path = '/content/drive/MyDrive/bharthnatyam/IMAGE - DATASET'\n",
        "\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(folder_path):\n",
        "    raise Exception(f\"The folder {folder_path} does not exist. Please check the path.\")\n",
        "else:\n",
        "    print(\"Folder Loaded Successfully\")"
      ],
      "metadata": {
        "id": "fJtU7Rblx9pG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pathlib\n",
        "# Define the directory path\n",
        "data_dir = pathlib.Path('/content/drive/MyDrive/bharthnatyam/IMAGE - DATASET')\n",
        "# Specify the image file extensions to look for\n",
        "image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff'}\n",
        "# Use pathlib to find all image files in the directory and subdirectories\n",
        "image_files = [f for f in data_dir.rglob('*') if f.suffix.lower() in image_extensions]\n",
        "# Count the number of image files\n",
        "num_images = len(image_files)\n",
        "print(f\"Number of images: {num_images}\")\n"
      ],
      "metadata": {
        "id": "TuB99RRByKy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load data using a Keras utility\n",
        "Next, load these images off disk using the helpful tf.keras.utils.image_dataset_from_directory utility. This will take you from a directory of images on disk to a tf.data.Dataset in just a couple lines of code. If you like, you can also write your own data loading code from scratch by visiting the Load and preprocess images tutorial."
      ],
      "metadata": {
        "id": "wor1KEaayRby"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create a dataset\n",
        "Define some parameters for the loader:"
      ],
      "metadata": {
        "id": "gOPdueetya61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180"
      ],
      "metadata": {
        "id": "PF9m_a2GyaLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "LeZ3s2ocyMPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "fQPAc2ITyvcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "zCuj_S4TyzND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize the data\n",
        "Here are the first nine images from the training dataset:"
      ],
      "metadata": {
        "id": "d410tfl6y1W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "MNhkdJaKy0FJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "id": "sH9RXME6y8Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Configure the dataset for performance\n",
        "Make sure to use buffered prefetching, so you can yield data from disk without having I/O become blocking. These are two important methods you should use when loading data:\n",
        "\n",
        "Dataset.cache keeps the images in memory after they're loaded off disk during the first epoch. This will ensure the dataset does not become a bottleneck while training your model. If your dataset is too large to fit into memory, you can also use this method to create a performant on-disk cache.\n",
        "Dataset.prefetch overlaps data preprocessing and model execution while training."
      ],
      "metadata": {
        "id": "RJKL3ZEUzDFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "FWV7LGWYzBUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Standardize the data\n",
        "The RGB channel values are in the [0, 255] range. This is not ideal for a neural network; in general you should seek to make your input values small.\n",
        "\n",
        "Here, you will standardize values to be in the [0, 1] range by using tf.keras.layers.Rescaling:"
      ],
      "metadata": {
        "id": "hfaEpnz3zP0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "Pf6zioGPzKCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))\n"
      ],
      "metadata": {
        "id": "zSNIDYu8zWvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#A basic Keras model\n",
        "###Create the model\n",
        "The Keras Sequential model consists of three convolution blocks (tf.keras.layers.Conv2D) with a max pooling layer (tf.keras.layers.MaxPooling2D) in each of them. There's a fully-connected layer (tf.keras.layers.Dense) with 128 units on top of it that is activated by a ReLU activation function ('relu'). This model has not been tuned for high accuracy; the goal of this tutorial is to show a standard approach."
      ],
      "metadata": {
        "id": "TxzhCLCjzgas"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "metadata": {
        "id": "DjIjE_fczokU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the model\n"
      ],
      "metadata": {
        "id": "3bldwcrVznum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "oQ7vCcyhzvtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model summary"
      ],
      "metadata": {
        "id": "-6xf-0oqz2XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "qd7OnqNtz5KU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "Yb71EzU6z_hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "j4gB5ws60Aoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Visualize training results\n",
        "Create plots of the loss and accuracy on the training and validation sets:"
      ],
      "metadata": {
        "id": "mp7VG-PJ1kWY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yKWjGus51qMo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overfitting\n"
      ],
      "metadata": {
        "id": "AOGcaUgp2QX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Data augmentation\n"
      ],
      "metadata": {
        "id": "Cfa3Bf5g2S93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(img_height,\n",
        "                                  img_width,\n",
        "                                  3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")\n",
        "     "
      ],
      "metadata": {
        "id": "y7jZ3MH52Yr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")\n"
      ],
      "metadata": {
        "id": "tJMqrhJP2dzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dropout\n",
        "Another technique to reduce overfitting is to introduce dropout{:.external} regularization to the network.\n",
        "\n",
        "When you apply dropout to a layer, it randomly drops out (by setting the activation to zero) a number of output units from the layer during the training process. Dropout takes a fractional number as its input value, in the form such as 0.1, 0.2, 0.4, etc. This means dropping out 10%, 20% or 40% of the output units randomly from the applied layer.\n",
        "\n",
        "Create a new neural network with tf.keras.layers.Dropout before training it using the augmented images:"
      ],
      "metadata": {
        "id": "-sPo-93u2j_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes, name=\"outputs\")\n",
        "])"
      ],
      "metadata": {
        "id": "oeD6uWra2t2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile and train the model"
      ],
      "metadata": {
        "id": "vdp8KDxN36xS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "cwefGK9p36Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "id": "1wZNGg5y35xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 15\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "id": "GR0ih1oF4IOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualize training results\n",
        "After applying data augmentation and tf.keras.layers.Dropout, there is less overfitting than before, and training and validation accuracy are closer aligned:"
      ],
      "metadata": {
        "id": "Po0FYS-O4MT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yo88Pkd54L0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Predict on new data\n",
        "Use your model to classify an image that wasn't included in the training or validation sets.\n",
        "\n",
        "Note: Data augmentation and dropout layers are inactive at inference time."
      ],
      "metadata": {
        "id": "sItb5xvu5erO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to your image file directly\n",
        "test_path = \"/content/drive/MyDrive/bharthnatyam/IMAGE - DATASET/Class 10 - Natta Adavu 10/Class 10 - Natta Adavu 10_0005.jpg\"\n",
        "\n",
        "# Load and preprocess the image\n",
        "img = tf.keras.utils.load_img(test_path, target_size=(img_height, img_width))\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "# Output the prediction result\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")\n"
      ],
      "metadata": {
        "id": "2r4Tup1Q5nEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predict on Test data"
      ],
      "metadata": {
        "id": "IBmgtiUP5sSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# Define the path to your image file directly\n",
        "test_path = \"/content/drive/MyDrive/bharthnatyam/IMAGE - DATASET/Class 10 - Natta Adavu 10/Class 10 - Natta Adavu 10_0005.jpg\"\n",
        "\n",
        "# Load and preprocess the image\n",
        "img = tf.keras.utils.load_img(test_path, target_size=(img_height, img_width))\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create a batch\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "# Get the prediction result\n",
        "prediction_text = \"This image most likely belongs to {} with a {:.2f} percent confidence.\".format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        "\n",
        "# Load the image using PIL for display\n",
        "img_pil = Image.open(test_path).resize((img_width, img_height))\n",
        "\n",
        "# Create a matplotlib figure\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(img_pil)\n",
        "ax.axis('off')  # Hide axes\n",
        "\n",
        "# Add the prediction text\n",
        "plt.text(\n",
        "    img_width // 2, img_height // 2, prediction_text,\n",
        "    color='white', fontsize=12, ha='center', va='center',\n",
        "    bbox=dict(facecolor='black', alpha=0.7, edgecolor='none', boxstyle='round,pad=0.5')\n",
        ")\n",
        "\n",
        "# Display the image with the text\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "96BK1-sO5x1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use TensorFlow Lite\n",
        "TensorFlow Lite is a set of tools that enables on-device machine learning by helping developers run their models on mobile, embedded, and edge devices."
      ],
      "metadata": {
        "id": "dz5pDhuy53eO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert the Keras Sequential model to a TensorFlow Lite model\n",
        "To use the trained model with on-device applications, first convert it to a smaller and more efficient model format called a TensorFlow Lite model.\n",
        "\n",
        "In this example, take the trained Keras Sequential model and use tf.lite.TFLiteConverter.from_keras_model to generate a TensorFlow Lite model:"
      ],
      "metadata": {
        "id": "xQ2tnmAl2hRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model.\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model.\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "0N8qdKgs6F0S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}